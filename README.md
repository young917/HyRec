# Kronecker Generative Models for Power Law Patterns in Real-World Hypergraphs

We provide datasets and source code for (1) **Discoveries** of log-logistic or power-law patterns in real-world hypergraphs and (2) **HyperK** which is a hypergraph generator based on kronecker product and **SingFit** for estimating initiator

```
# File Organization
|__ Property/                   
    |__ dataset/                # real-world hypergraph: i-th line indicates i-th hypergraph where included nodes are 
    |__ analyze/                # used for plotting discoveries or evaluation of hypergraph generators
    |__ src/                    # used for computing nine properties
|__ Model/                      
    |__ input/                  # real-world hypergraph same as the above but in different format: i-th line indicates {column index} {row index} {value} of incidence matrix
    |__ data/                   # save singular values of real-world hypergraphs
    |__ *.py                    # used for HyperK and SingFit

```

## (1) Discoveries

You can run *8* discoveries with thirteen datasets at the same time. The outputs will be saved in Property/results/answer/[data name] directory.
As following `run_discovery.sh`,
```
cd Property/
make
./bin/Sampling --inputpath ../dataset/${data name} --outputdir ./results/answer/${data name}/
cd src
python calculation_helper.py --inputpath ../../dataset/${data name} --outputdir ../results/answer/${data name}/ --sv
```

Then, you can plot the distributions with R2 scores and slopes as following `analyze/Analysis-Data.ipynb`,

## (2) HyperK and SingFit

We provide source code for training HyperK using SingFit

### How to Train HyperK

You can *train* HyperK by following `Model/run/run_{small, large}.sh`,
```
python main_sv.py train --dataset {data name}
                        --device {cuda number}
                        --gen_at_once
                        --numparam {parameter count constraint}
                        --lr {learning rate}
                        --approx {number of tie in training} --evalapprox {number of tie in generation}
                        --annealrate {annealing rate for tuning temperature in gumbel softmax}
```

You can *generate (or extrapolate)* a hypergraph using the trained HyperK by following `Model/run/run_predict_{small, large}.sh`,
```
python main.py eval --dataset {target_data_name} --load_path {trained_model_path} --gen_at_once
```

### How to Evaluate HyperK

You can compute nine properties from the hypergraphs generated by HyperK,
```
cd Property/results/hyperk/
python make_input_list.py --dataname {data_name} # make shell script for computing nine properties from all generated hypergraphs in Model/result/{data_name}/*
cd ../../run
./run_hyperk_{data_name}.sh # run the script for computing properties
```

You can also compute nine properties from the hypergraphs extrapolated by HyperK,
```
cd Property/results/hyperk/
python make_input_list_half.py --dataname {half_data_name} # make shell script for computing nine properties from all extrapolated hypergraphs in Model/result/{half_data_name}/full/*
cd ../../run
./run_hyperk_{half_data_name}.sh # run the script for computing properties

cd Property/results/hyperk_half/
python make_input_list.py --dataname {half_data_name} # make shell script for computing nine properties from all half-sized hypergraphs in Model/result/{half_data_name}/*
cd ../../run
./run_hyperk_{half_data_name}-half.sh # run the script for computing properties
```


You can compare the distributions from generators by `Property/analyze/Compare Figure {Extrapolation}.ipynb`.

You can also evaluate the generators by rankings and z-scores by `Property/analyze/Compare Table {Extrapolation}.ipynb`.


- - -

## Environment

The environment of running codes is specified in `requirements.txt`
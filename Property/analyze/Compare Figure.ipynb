{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-stationery",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"E\", \"V\", \n",
    " \"deg score\", \"deg coef\", \"sz score\", \"sz coef\",\n",
    " \"pd score\", \"pd coef\", \"its score\", \"its coef\", \n",
    " \"cc score\", \"cc coef\", \"cch score\", \"cch coef\", \n",
    " \"dst score\", \"dst coef\", \"ov score\", \"ov coef\",\n",
    " \"lsv\", \"sv score\", \"sv coef\", \"eff\"]\n",
    "\n",
    "property_list = [\"NumHedge\", \"NumNode\", \"degree\", \"size\", \"pairdeg\", \"intersection\",\n",
    "             \"clusteringcoef\", \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\",\n",
    "             \"LargestSV\", \"sv\", \"effdiam\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"NumHedge\": \"E\", \"NumNode\": \"V\",\n",
    "    \"degree\": \"deg\", \"pairdeg\": \"pd\",\n",
    "    \"intersection\": \"its\", \"size\": \"sz\",\n",
    "    \"clusteringcoef\": \"cc\", \"clusteringcoef_hedge\": \"cch\",\n",
    "    \"density_dist\": \"dst\", \"overlapness_dist\": \"ov\",\n",
    "    \"LargestSV\": \"lsv\", \"sv\": \"sv\", \n",
    "    \"effdiam\": \"eff\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def linearregression(X, Y, nolog=False):\n",
    "    if len(X) == 0:\n",
    "        return 0, 0, [0], 0\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y).reshape(-1, 1)\n",
    "    if nolog is False:\n",
    "        X = np.log2(X)\n",
    "        Y = np.log2(Y)\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    score = reg.score(X, Y)\n",
    "    coef = reg.coef_\n",
    "    assert len(coef) == 1\n",
    "    coef = coef[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "    pred = reg.predict(X).flatten()\n",
    "    pred = np.exp2(pred)\n",
    "\n",
    "    return score, coef, pred, intercept\n",
    "\n",
    "def read_properties(dataname, algoname, modelindex=-1):\n",
    "    if \"answer\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \".txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hypercl\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_cl.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperlap\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_lap.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperpa\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_pa.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"thera\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    elif \"hyperff\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    else:\n",
    "        graphpath = \"../results/{}/{}/{}/hypergraph.txt\".format(algoname, dataname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "\n",
    "    return_dict = {}\n",
    "    dist = {}\n",
    "    print(graphpath)\n",
    "    \n",
    "    # Num Nodes & Num Edges\n",
    "    numhedge = 0\n",
    "    nodeset = set()\n",
    "    with open(graphpath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            hedge = line.rstrip().split(\",\")\n",
    "            for v in hedge:\n",
    "                nodeset.add(int(v))\n",
    "            numhedge += 1\n",
    "    numnode = len(nodeset)\n",
    "    return_dict[\"NumHedge\"] = numhedge\n",
    "    return_dict[\"NumNode\"] = numnode  \n",
    "    dist[\"NumHedge\"] = numhedge\n",
    "    dist[\"NumNode\"] = numnode    \n",
    "    \n",
    "    for distname in [\"degree\", \"pairdeg\", \"intersection\", \"size\"]:\n",
    "        dist[distname] = {}\n",
    "        X = []\n",
    "        with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                val, pdf = line.rstrip().split(\",\")\n",
    "                val, pdf = float(val), float(pdf)\n",
    "                if pdf == 0.0 or val == 0.0:\n",
    "                    continue\n",
    "                dist[distname][val] = pdf\n",
    "                X.append(val)\n",
    "        X = sorted(X)\n",
    "        Y = [dist[distname][x] for x in X]\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[distname] = (score, coef)\n",
    "        \n",
    "    for distname in [\"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "        dist[distname] = defaultdict(list)\n",
    "        X = []\n",
    "        try:\n",
    "            with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    val, pdf = line.rstrip().split(\",\")\n",
    "                    val, pdf = float(val), float(pdf)\n",
    "                    if val == 0.0 or pdf == 0.0:\n",
    "                        continue\n",
    "                    dist[distname][val].append(pdf)\n",
    "                    X.append(val)\n",
    "            X = sorted(X)\n",
    "            Y = []\n",
    "            for x in X:\n",
    "                y = np.mean(dist[distname][x])\n",
    "                dist[distname][x] = y\n",
    "                if y > 0:\n",
    "                    Y.append(y)\n",
    "                else:\n",
    "                    Y.append(1)\n",
    "            score, coef, pred, _ = linearregression(X, Y)\n",
    "            return_dict[distname] = (score, coef)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    with open(outputdir + \"sv.txt\", \"r\") as f:\n",
    "        tmp = {}\n",
    "        X = []\n",
    "        lsv = 0\n",
    "        for li, line in enumerate(f.readlines()):\n",
    "            sv = float(line.rstrip())\n",
    "            if li == 0:\n",
    "                lsv = sv\n",
    "            tmp[li + 1] = sv\n",
    "            X.append(li + 1)\n",
    "        X = sorted(X)\n",
    "        if dataname not in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:min(1000, int(len(X) * 0.5))]\n",
    "        elif dataname in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:1000]\n",
    "        elif dataname in [ \"coauth-MAG-Geology-full\", \"coauth-MAG-History-full\"]:\n",
    "            X = X[:500]\n",
    "        Y = [tmp[x] for x in X]\n",
    "\n",
    "        dist[\"sv\"] = {}\n",
    "        for x,y in zip(X, Y):\n",
    "            dist[\"sv\"][x] = y\n",
    "        dist[\"LargestSV\"] = lsv\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[\"sv\"] = (score, coef)\n",
    "\n",
    "    # EffDiam\n",
    "    with open(outputdir + \"effdiameter.txt\", \"r\") as f:\n",
    "        effdiam = 0\n",
    "        for line in f.readlines():\n",
    "            effdiam = float(line.rstrip())\n",
    "        return_dict[\"effdiam\"] = effdiam\n",
    "        dist[\"effdiam\"] = effdiam\n",
    "\n",
    "    return return_dict, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(_dict):\n",
    "    cumulated_x = sorted(list(_dict.keys()))\n",
    "    cdf = {}\n",
    "    cum = 0\n",
    "\n",
    "    for _x in cumulated_x:\n",
    "        cum += _dict[_x]\n",
    "        cdf[_x] = cum\n",
    "        assert cum < 1.1\n",
    "        \n",
    "    return cdf\n",
    "\n",
    "def get_cumul_dist(dict_x1, dict_x2):\n",
    "    cdf1 = get_cdf(dict_x1)\n",
    "    x1 = list(cdf1.keys())\n",
    "    cdf2 = get_cdf(dict_x2)\n",
    "    x2 = list(cdf2.keys())\n",
    "    \n",
    "    cum1, cum2 = 0, 0\n",
    "    maxdiff = 0\n",
    "    for x in sorted(list(set(x1 + x2))):\n",
    "        if x in x1:\n",
    "            cum1 = cdf1[x]\n",
    "        if x in x2:\n",
    "            cum2 = cdf2[x]\n",
    "        if abs(cum1 - cum2) > maxdiff:\n",
    "            maxdiff = abs(cum1 - cum2)\n",
    "    \n",
    "    return maxdiff\n",
    "\n",
    "    \n",
    "def get_rmse_dist(dict_x1, dict_x2, normalize=False):\n",
    "    total = 0\n",
    "    \n",
    "    maxy1 = 0\n",
    "    \n",
    "    x1s = list(dict_x1.keys())\n",
    "    x2s = list(dict_x2.keys())\n",
    "    for x in set(x1s + x2s):\n",
    "        y1, y2 = 0, 0\n",
    "        if x in x1s:\n",
    "            y1 = dict_x1[x]\n",
    "            if maxy1 < y1:\n",
    "                maxy1 = y1\n",
    "        if x in x2s:\n",
    "            y2 = dict_x2[x]\n",
    "        \n",
    "        total += (y1 - y2) ** 2\n",
    "    \n",
    "    total /= len(set(x1s + x2s))\n",
    "    total = total ** 0.5\n",
    "    \n",
    "    if normalize:\n",
    "        total /= maxy1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_result_dir = \"hyperk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-guard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabeldict = {\n",
    "    \"degree\": \"Node degree\",\n",
    "    \"size\": \"Hyperedge size\",\n",
    "    \"pairdeg\": \"Degree of node pairs\",\n",
    "    \"intersection\": \"Intersection size\",\n",
    "    \"sv\": \"Rank\",\n",
    "    \"clusteringcoef_hedge\": \"Node degree\",\n",
    "    \"density_dist\": \"# of nodes\",\n",
    "    \"overlapness_dist\": \"# of nodes\"\n",
    "}\n",
    "\n",
    "ylabeldict = {\n",
    "    \"degree\": \"OddsRatio\",\n",
    "    \"size\": \"OddsRatio\",\n",
    "    \"pairdeg\": \"PDF\",\n",
    "    \"intersection\": 'PDF',\n",
    "    \"sv\": \"Singular value\",\n",
    "    \"clusteringcoef_hedge\": \"# of inter- \\n secting pairs\",\n",
    "    \"density_dist\": \"# of hyperedges\",\n",
    "    \"overlapness_dist\": r\"$\\sum$ hyperedge sizes\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    \"answer\": \"black\",\n",
    "    \n",
    "    \"hyperk\": \"#4daf4a\",\n",
    "    \"hypercl\": \"#e6ab02\",\n",
    "    \"hyperlap\": \"#377eb8\",\n",
    "    \"hyperpa\": \"#984ea3\",\n",
    "    \"thera\": \"#ff7f00\",\n",
    "    \"hyperff\": \"#e41a1c\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataname = \"email-Enron-full\"\n",
    "# dataname = \"email-Eu-full\"\n",
    "# dataname = \"NDC-classes-full\"\n",
    "# dataname = \"NDC-substances-full\"\n",
    "# dataname = \"contact-primary-school\"\n",
    "# dataname = \"contact-high-school\"\n",
    "# dataname = \"tags-ask-ubuntu\"\n",
    "# dataname = \"tags-math-sx\"\n",
    "# dataname = \"threads-ask-ubuntu\"\n",
    "dataname = \"threads-math-sx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "distset = [\"degree\", \"size\", \"pairdeg\", \"intersection\", \"sv\", \n",
    "           \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fflist = {\n",
    "    \"email-Enron-full\": [\"0.51_0.2\"],\n",
    "    \"email-Eu-full\": [\"0.51_0.3\"],\n",
    "    \"contact-high-school\": [\"0.51_0.3\"],\n",
    "    \"contact-primary-school\": [\"0.51_0.3\"],\n",
    "    \"NDC-classes-full\": [\"0.45_0.3\"],\n",
    "    \"NDC-substances-full\": [\"0.45_0.3\"],\n",
    "    \"tags-ask-ubuntu\": [\"0.51_0.3\"],\n",
    "    \"tags-math-sx\": [\"0.51_0.3\"],\n",
    "    \"threads-ask-ubuntu\": [\"0.45_0.2\"],\n",
    "    \"threads-math-sx\": [\"0.45_0.2\"]\n",
    "}\n",
    "\n",
    "trlist = {\n",
    "    \"email-Enron-full\": [\"12_0.7_6.0\"], \n",
    "    \"email-Eu-full\": [\"15_0.5_6.0\"],\n",
    "    \"contact-high-school\": [\"15_0.7_2.0\"], \n",
    "    \"contact-primary-school\": [\"15_0.5_2.0\"],\n",
    "    \"NDC-classes-full\": [\"15_0.9_6.0\"],\n",
    "    \"NDC-substances-full\": [\"15_0.5_6.0\"],\n",
    "    \"tags-ask-ubuntu\": [\"8_0.5_2.0\"], \n",
    "    \"tags-math-sx\": [\"8_0.9_2.0\"], \n",
    "    \"threads-ask-ubuntu\": [\"8_0.5_6.0\"], \n",
    "    \"threads-math-sx\": [\"8_0.5_6.0\"], \n",
    "}\n",
    "\n",
    "\n",
    "namelist = [(\"answer\", -1)]\n",
    "if len(trlist[dataname]) > 0:\n",
    "    namelist.append((\"thera\", trlist[dataname][0]))\n",
    "namelist.append((\"hyperlap\", -1))    \n",
    "namelist.append((\"hypercl\", -1))\n",
    "if dataname != \"email-Enron-full\":\n",
    "    namelist.append((\"hyperpa\", -1))\n",
    "if len(fflist[dataname]) > 0:\n",
    "    namelist.append((\"hyperff\", fflist[dataname][0]))\n",
    "if len(kronlist[dataname]) > 0:\n",
    "    namelist.append((\"hyperk\", 0)) # assume there exist just one generated hypergraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    \"answer\": \"ANSWER\",\n",
    "    \"hypercl\" : \"HyperCL\",\n",
    "    \"hyperlap\" : \"HyperLAP\",\n",
    "    \"hyperpa\" : \"HyperPA\",\n",
    "    \"hyperff\" : \"HyperFF\",\n",
    "    \"thera\" : \"THera\", \n",
    "    \"hyperk\" : \"HyperK\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-concept",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for distname in distset:\n",
    "    outputpath = \"figure/fit/\" + dataname + \"/\"\n",
    "    if os.path.isdir(outputpath) is False:\n",
    "        os.makedirs(outputpath)\n",
    "    outputpath += distname + \".jpg\"\n",
    "\n",
    "    plt.figure(figsize=(5,4), dpi=100)\n",
    "    for (name, idx) in namelist:\n",
    "        print(dataname, name, idx)\n",
    "        ret, dist = read_properties(dataname, name, idx)\n",
    "        if name == \"answer\":\n",
    "            ret_answer = ret\n",
    "            dist_answer = dist \n",
    "        \n",
    "        algoname = rename[name]\n",
    "\n",
    "        # PLOT!\n",
    "        target_dist = dist[distname]\n",
    "        x = list(target_dist.keys())\n",
    "        y = [target_dist[_x] for _x in x]\n",
    "        score, coef, pred, intercept = linearregression(x, y)\n",
    "        \n",
    "        if name in [\"answer\"]:\n",
    "            plt.scatter(x, y, label=algoname, c=color[name], alpha=0.6, s=130)\n",
    "        elif name in [\"hypercl\",  \"hyperlap\", \"hyperff\", \"thera\"]:\n",
    "            plt.scatter(x, y, label=algoname, c=color[name], alpha=0.7, s=40)\n",
    "        else:\n",
    "            plt.scatter(x, y, label=algoname, c=color[name], alpha=0.9, s= 40)\n",
    "        \n",
    "    plt.xscale(\"log\", base=2)\n",
    "    plt.yscale(\"log\", base=2)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(labelcolor='#4B4B4B', labelsize=22)\n",
    "    plt.xlabel(xlabeldict[distname], fontsize=24)\n",
    "    plt.ylabel(ylabeldict[distname], fontsize=24)\n",
    "        \n",
    "#     plt.legend(bbox_to_anchor=(1,1.05))\n",
    "#     plt.title(\"%s\" % (dataname))\n",
    "#     plt.savefig(outputpath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

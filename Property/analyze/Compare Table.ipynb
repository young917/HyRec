{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-vessel",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"E\", \"V\", \n",
    " \"deg score\", \"deg coef\", \"sz score\", \"sz coef\",\n",
    " \"pd score\", \"pd coef\", \"its score\", \"its coef\", \n",
    " \"cc score\", \"cc coef\", \"cch score\", \"cch coef\", \n",
    " \"dst score\", \"dst coef\", \"ov score\", \"ov coef\",\n",
    " \"lsv\", \"sv score\", \"sv coef\", \"eff\"]\n",
    "\n",
    "property_list = [\"NumHedge\", \"NumNode\", \"degree\", \"size\", \"pairdeg\", \"intersection\",\n",
    "             \"clusteringcoef\", \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\",\n",
    "             \"LargestSV\", \"sv\", \"effdiam\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"NumHedge\": \"E\", \"NumNode\": \"V\",\n",
    "    \"degree\": \"deg\", \"pairdeg\": \"pd\",\n",
    "    \"intersection\": \"its\", \"size\": \"sz\",\n",
    "    \"clusteringcoef\": \"cc\", \"clusteringcoef_hedge\": \"cch\",\n",
    "    \"density_dist\": \"dst\", \"overlapness_dist\": \"ov\",\n",
    "    \"LargestSV\": \"lsv\", \"sv\": \"sv\", \n",
    "    \"effdiam\": \"eff\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def linearregression(X, Y, nolog=False):\n",
    "    if len(X) == 0:\n",
    "        return 0, 0, [0], 0\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y).reshape(-1, 1)\n",
    "    if nolog is False:\n",
    "        X = np.log2(X)\n",
    "        Y = np.log2(Y)\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    score = reg.score(X, Y)\n",
    "    coef = reg.coef_\n",
    "    assert len(coef) == 1\n",
    "    coef = coef[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "    pred = reg.predict(X).flatten()\n",
    "    pred = np.exp2(pred)\n",
    "\n",
    "    return score, coef, pred, intercept\n",
    "\n",
    "def read_properties(dataname, algoname, modelindex=-1):\n",
    "    if \"answer\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \".txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hypercl\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_cl.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperunif\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_unif.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperlap\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_lap.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperpa\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_pa.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"thera\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    elif \"hyperff\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    else:\n",
    "        graphpath = \"../results/{}/{}/{}/hypergraph.txt\".format(algoname, dataname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "\n",
    "    return_dict = {}\n",
    "    dist = {}\n",
    "    print(graphpath)\n",
    "    \n",
    "    # Num Nodes & Num Edges\n",
    "    numhedge = 0\n",
    "    nodeset = set()\n",
    "    with open(graphpath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            hedge = line.rstrip().split(\",\")\n",
    "            for v in hedge:\n",
    "                nodeset.add(int(v))\n",
    "            numhedge += 1\n",
    "    numnode = len(nodeset)\n",
    "    return_dict[\"NumHedge\"] = numhedge\n",
    "    return_dict[\"NumNode\"] = numnode  \n",
    "    dist[\"NumHedge\"] = numhedge\n",
    "    dist[\"NumNode\"] = numnode    \n",
    "    \n",
    "    for distname in [\"degree\", \"pairdeg\", \"intersection\", \"size\"]:\n",
    "        dist[distname] = {}\n",
    "        X = []\n",
    "        with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                val, pdf = line.rstrip().split(\",\")\n",
    "                val, pdf = float(val), float(pdf)\n",
    "                if pdf == 0.0 or val == 0.0:\n",
    "                    continue\n",
    "                dist[distname][val] = pdf\n",
    "                X.append(val)\n",
    "        X = sorted(X)\n",
    "        Y = [dist[distname][x] for x in X]\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[distname] = (score, coef)\n",
    "        \n",
    "    for distname in [\"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "        dist[distname] = defaultdict(list)\n",
    "        X = []\n",
    "        try:\n",
    "            with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    val, pdf = line.rstrip().split(\",\")\n",
    "                    val, pdf = float(val), float(pdf)\n",
    "                    if val == 0.0 or pdf == 0.0:\n",
    "                        continue\n",
    "                    dist[distname][val].append(pdf)\n",
    "                    X.append(val)\n",
    "            X = sorted(X)\n",
    "            Y = []\n",
    "            for x in X:\n",
    "                y = np.mean(dist[distname][x])\n",
    "                dist[distname][x] = y\n",
    "                if y > 0:\n",
    "                    Y.append(y)\n",
    "                else:\n",
    "                    Y.append(1)\n",
    "            score, coef, pred, _ = linearregression(X, Y)\n",
    "            return_dict[distname] = (score, coef)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # SV    \n",
    "    with open(outputdir + \"sv.txt\", \"r\") as f:\n",
    "        tmp = {}\n",
    "        X = []\n",
    "        lsv = 0\n",
    "        for li, line in enumerate(f.readlines()):\n",
    "            sv = float(line.rstrip())\n",
    "            if li == 0:\n",
    "                lsv = sv\n",
    "            tmp[li + 1] = sv\n",
    "            X.append(li + 1)\n",
    "        X = sorted(X)\n",
    "        if dataname not in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:min(1000, int(len(X) * 0.5))]\n",
    "        elif dataname in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:1000]\n",
    "        elif dataname in [ \"coauth-MAG-Geology-full\", \"coauth-MAG-History-full\"]:\n",
    "            X = X[:500]\n",
    "        Y = [tmp[x] for x in X]\n",
    "\n",
    "        dist[\"sv\"] = {}\n",
    "        for x,y in zip(X, Y):\n",
    "            dist[\"sv\"][x] = y\n",
    "        dist[\"LargestSV\"] = lsv\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[\"sv\"] = (score, coef)\n",
    "\n",
    "\n",
    "    # EffDiam\n",
    "    with open(outputdir + \"effdiameter.txt\", \"r\") as f:\n",
    "        effdiam = 0\n",
    "        for line in f.readlines():\n",
    "            effdiam = float(line.rstrip())\n",
    "        return_dict[\"effdiam\"] = effdiam\n",
    "        dist[\"effdiam\"] = effdiam\n",
    "    \n",
    "    # SAVE\n",
    "    with open(outputdir + \"property.txt\", \"w\") as f:\n",
    "        f.write(\",\".join(columns) + \"\\n\")\n",
    "        tmp = []\n",
    "        for name in property_list:\n",
    "            if name in [\"LargestSV\", \"effdiam\", \"NumHedge\", \"NumNode\"]:\n",
    "                tmp.append(str(return_dict[name]))\n",
    "            else:\n",
    "                tmp1, tmp2 = return_dict[name]\n",
    "                tmp.append(str(tmp1))\n",
    "                tmp.append(str(tmp2))\n",
    "        f.write(\",\".join(tmp))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    return return_dict, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(_dict):\n",
    "    cumulated_x = sorted(list(_dict.keys()))\n",
    "    cdf = {}\n",
    "    cum = 0\n",
    "\n",
    "    for _x in cumulated_x:\n",
    "        cum += _dict[_x]\n",
    "        cdf[_x] = cum\n",
    "        assert cum < 1.1\n",
    "        \n",
    "    return cdf\n",
    "\n",
    "def get_cumul_dist(dict_x1, dict_x2):\n",
    "    cdf1 = get_cdf(dict_x1)\n",
    "    x1 = list(cdf1.keys())\n",
    "    cdf2 = get_cdf(dict_x2)\n",
    "    x2 = list(cdf2.keys())\n",
    "    \n",
    "    cum1, cum2 = 0, 0\n",
    "    maxdiff = 0\n",
    "    maxdiff_pos = 0\n",
    "    for x in sorted(list(set(x1 + x2))):\n",
    "        if x in x1:\n",
    "            cum1 = cdf1[x]\n",
    "        if x in x2:\n",
    "            cum2 = cdf2[x]\n",
    "        if abs(cum1 - cum2) > maxdiff:\n",
    "            maxdiff = abs(cum1 - cum2)\n",
    "            maxdiff_pos = x\n",
    "    print(x)\n",
    "    \n",
    "    return maxdiff\n",
    "\n",
    "    \n",
    "def get_rmse_dist(dict_x1, dict_x2, set_length=False, normalize=False):\n",
    "    total = 0\n",
    "    maxy1 = 0\n",
    "    \n",
    "    x1s = list(dict_x1.keys())\n",
    "    x2s = list(dict_x2.keys())\n",
    "    \n",
    "    if set_length:\n",
    "        keys = x1s\n",
    "    else:\n",
    "        keys = set(x1s+x2s)\n",
    "    \n",
    "    for x in keys:\n",
    "        y1, y2 = 0, 0\n",
    "        if x in x1s:\n",
    "            y1 = dict_x1[x]\n",
    "            if maxy1 < y1:\n",
    "                maxy1 = y1\n",
    "        if x in x2s:\n",
    "            y2 = dict_x2[x]\n",
    "        \n",
    "        total += (y1 - y2) ** 2\n",
    "    \n",
    "    total /= len(keys)\n",
    "    total = total ** 0.5\n",
    "    \n",
    "    if normalize:\n",
    "        total /= maxy1\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataname = \"email-Enron-full\"\n",
    "# dataname = \"email-Eu-full\" \n",
    "# dataname = \"NDC-classes-full\"\n",
    "# dataname = \"NDC-substances-full\"\n",
    "# dataname = \"contact-primary-school\"\n",
    "# dataname = \"contact-high-school\"\n",
    "# dataname = \"tags-ask-ubuntu\"\n",
    "dataname = \"tags-math-sx\"\n",
    "# dataname = \"threads-ask-ubuntu\"\n",
    "# dataname = \"threads-math-sx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "fflist = {\n",
    "    \"email-Enron-full\": [\"0.51_0.2\"],\n",
    "    \"email-Eu-full\": [\"0.51_0.3\"],\n",
    "    \"contact-high-school\": [\"0.51_0.3\"],\n",
    "    \"contact-primary-school\": [\"0.51_0.3\"],\n",
    "    \"NDC-classes-full\": [\"0.45_0.3\"],\n",
    "    \"NDC-substances-full\": [\"0.45_0.3\"],\n",
    "    \"tags-ask-ubuntu\": [\"0.51_0.3\"],\n",
    "    \"tags-math-sx\": [\"0.51_0.3\"],\n",
    "    \"threads-ask-ubuntu\": [\"0.45_0.2\"],\n",
    "    \"threads-math-sx\": [\"0.45_0.2\"]\n",
    "}\n",
    "\n",
    "trlist = {\n",
    "    \"email-Enron-full\": [\"12_0.7_6.0\"], \n",
    "    \"email-Eu-full\": [\"15_0.5_6.0\"], \n",
    "    \"contact-high-school\": [\"15_0.7_2.0\"], \n",
    "    \"contact-primary-school\": [\"15_0.5_2.0\"], \n",
    "    \"NDC-classes-full\": [\"15_0.9_6.0\"],\n",
    "    \"NDC-substances-full\": [\"15_0.5_6.0\"], \n",
    "    \"tags-ask-ubuntu\": [\"8_0.5_2.0\"], \n",
    "    \"tags-math-sx\": [\"8_0.9_2.0\"],\n",
    "    \"threads-ask-ubuntu\": [\"8_0.5_6.0\"], \n",
    "    \"threads-math-sx\": [\"8_0.5_6.0\"], \n",
    "}\n",
    "\n",
    "namelist = [(\"answer\", -1)]\n",
    "if len(trlist[dataname]) > 0:\n",
    "    namelist.append((\"thera\", trlist[dataname][0]))\n",
    "namelist.append((\"hyperlap\", -1))    \n",
    "if dataname != \"email-Enron-full\":\n",
    "    namelist.append((\"hyperpa\", -1))    \n",
    "namelist.append((\"hypercl\", -1))\n",
    "if len(fflist[dataname]) > 0:\n",
    "    namelist.append((\"hyperff\", fflist[dataname][0]))\n",
    "if len(kronlist[dataname]) > 0:\n",
    "    namelist.append((\"hyperk\", 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-roots",
   "metadata": {},
   "source": [
    "# WRITE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_list = [\"degree\", \"size\", \"pairdeg\", \"intersection\",\"sv\", \n",
    "             \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\", \"effdiam\"]\n",
    "\n",
    "evallist = ['deg', 'sz', 'pd', 'its', 'cch', 'dst', 'ov', 'sv', 'eff'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = \"csv/sv_fit/\"\n",
    "outputpath = outputdir + dataname + \".txt\"\n",
    "if os.path.isdir(outputdir) is False:\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-motivation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [column_mapping[prop] for prop in property_list]\n",
    "with open(outputpath, \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\", \"AlgoOpt\"] + columns) + \"\\n\")\n",
    "\n",
    "for name, modelindex in namelist:\n",
    "    ret, dist = read_properties(dataname, name, modelindex)\n",
    "    if name == \"answer\":\n",
    "        ret_answer = ret\n",
    "        dist_answer = dist   \n",
    "        continue\n",
    "\n",
    "    difflist = []\n",
    "    for prop in property_list:\n",
    "        if prop in [\"degree\", \"size\", \"pairdeg\", \"intersection\"]:\n",
    "            diff = get_cumul_dist(dist_answer[prop], dist[prop])\n",
    "        elif prop in [\"sv\"]:\n",
    "            diff = get_rmse_dist(dist_answer[prop], dist[prop], set_length=True, normalize=False)\n",
    "        elif prop in [\"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "            diff = get_rmse_dist(dist_answer[prop], dist[prop], normalize=False)\n",
    "        elif prop in [\"NumHedge\", \"NumNode\", \"LargestSV\", \"effdiam\"]:\n",
    "            diff = abs(dist[prop] - dist_answer[prop]) / dist_answer[prop]\n",
    "        difflist.append(str(diff))\n",
    "\n",
    "    with open(outputpath, \"a\") as f:\n",
    "        algoopt = str(modelindex)\n",
    "        algoname = name\n",
    "        f.write(\",\".join([algoname, algoopt] + difflist) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-corrections",
   "metadata": {},
   "source": [
    "# RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "d = d.sort_values(by=\"sv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "target = d[evallist]\n",
    "d['avg'] = target.mean(axis=1)\n",
    "d.to_csv(outputdir + dataname + \".txt\", index=False)\n",
    "\n",
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "d = d.sort_values(by=\"avg\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-heating",
   "metadata": {},
   "source": [
    "# RANK & NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Normalize Result\n",
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "for col in evallist:\n",
    "    if d[col].std() != 0:\n",
    "        d[col] = (d[col] - d[col].mean()) / d[col].std()\n",
    "norms = d[evallist]\n",
    "d['avg'] = norms.mean(axis=1)\n",
    "# d = d.sort_values(by=[\"avg\"], ascending=True)\n",
    "d.to_csv(outputdir + dataname + \"_norm.txt\", index=False)\n",
    "\n",
    "# Make Ranking Result\n",
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "for ename in evallist:\n",
    "    d[ename] = d[ename].abs().rank(method='min')\n",
    "ranks = d[evallist]\n",
    "d['avg'] = ranks.mean(axis=1)\n",
    "# d = d.sort_values(by=[\"avg\"], ascending=True)\n",
    "d.to_csv(outputdir + dataname + \"_rank.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norm\n",
    "nd = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "nd = nd.sort_values(by=[\"avg\"], ascending=True)\n",
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank\n",
    "rd = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "rd = rd.sort_values(by=[\"avg\"], ascending=True)\n",
    "rd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-meeting",
   "metadata": {},
   "source": [
    "# GET FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "algoname2agg = defaultdict(float)\n",
    "\n",
    "nd = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "nd = nd.sort_values(by=[\"avg\"], ascending=True)\n",
    "norder = 1\n",
    "for irow, row in nd.iterrows():\n",
    "    algoname = row[\"AlgoName\"]\n",
    "    algoname2agg[algoname] += (norder * 0.5)\n",
    "    norder += 1\n",
    "    \n",
    "rd = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "rd = rd.sort_values(by=[\"avg\"], ascending=True)\n",
    "rorder = 1\n",
    "for irow, row in rd.iterrows():\n",
    "    algoname = row[\"AlgoName\"]\n",
    "    algoname2agg[algoname] += (rorder * 0.5)\n",
    "    rorder += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir + dataname + \"_final.txt\", \"w\") as f:\n",
    "    for algoname in algoname2agg.keys():\n",
    "        f.write(algoname + \"\\t\" + str(algoname2agg[algoname]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-white",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-protocol",
   "metadata": {},
   "source": [
    "# AGGREGATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"email-Enron-full\", \"email-Eu-full\",\n",
    "           \"contact-high-school\", \"contact-primary-school\",\n",
    "          \"NDC-classes-full\", \"NDC-substances-full\"\n",
    "           ,\"tags-ask-ubuntu\", \"tags-math-sx\",\n",
    "          \"threads-ask-ubuntu\", \"threads-math-sx\"]\n",
    "\n",
    "algolist = [\"thera\", \"hyperlap\", \"hypercl\", \"hyperpa\", \"hyperff\", \"hyperk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_aggdata2norm = {}\n",
    "table_aggdata2rank = {}\n",
    "for dataname in dataset:\n",
    "    d = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in table_aggdata2norm:\n",
    "            table_aggdata2norm[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + [\"avg\"]:\n",
    "            table_aggdata2norm[algoname][evalname].append(row[evalname])\n",
    "    \n",
    "    d = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in table_aggdata2rank:\n",
    "            table_aggdata2rank[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + [\"avg\"]:\n",
    "            table_aggdata2rank[algoname][evalname].append(row[evalname])\n",
    "        \n",
    "        \n",
    "for algoname in algolist:\n",
    "    for evalname in evallist + [\"avg\"]:\n",
    "        table_aggdata2norm[algoname][evalname] = np.mean(table_aggdata2norm[algoname][evalname])\n",
    "        table_aggdata2rank[algoname][evalname] = np.mean(table_aggdata2rank[algoname][evalname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir + \"agg_norm_table\", \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\"] + evallist + [\"avg\"]) + \"\\n\")\n",
    "    for algoname in algolist:\n",
    "        f.write(\",\".join([algoname] + [str(table_aggdata2norm[algoname][evalname]) for evalname in evallist + [\"avg\"]]) + \"\\n\")\n",
    "        \n",
    "with open(outputdir + \"agg_rank_table\", \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\"] + evallist + [\"avg\"]) + \"\\n\")\n",
    "    for algoname in algolist:\n",
    "        f.write(\",\".join([algoname] + [str(table_aggdata2rank[algoname][evalname]) for evalname in evallist + [\"avg\"]]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = pd.read_csv(outputdir + \"agg_norm_table\")\n",
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.read_csv(outputdir + \"agg_rank_table\")\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-flesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-jones",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF PARAMETERS\n",
    "\n",
    "dataset2numparam = defaultdict(dict)\n",
    "\n",
    "for dataname in dataset:\n",
    "    answer_numhedge = 0\n",
    "    nodeset = set()\n",
    "    with open(\"../dataset/\" + dataname + \".txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            hedge = line.rstrip().split(\",\")\n",
    "            for v in hedge:\n",
    "                nodeset.add(int(v))\n",
    "            answer_numhedge += 1\n",
    "    answer_numnode = len(nodeset)\n",
    "    print(dataname, answer_numhedge, answer_numnode)\n",
    "\n",
    "\n",
    "    number_of_parameter = {}\n",
    "    if len(trlist[dataname]) > 0:\n",
    "        # tr : size = |E|\n",
    "        number_of_parameter[\"thera\"] = answer_numhedge + 4\n",
    "    # lap: size & degree = |V| + |E|\n",
    "    number_of_parameter[\"hyperlap\"] = answer_numhedge + answer_numnode\n",
    "    # cl: size & degree = |V| + |E|\n",
    "    number_of_parameter[\"hypercl\"] = answer_numhedge + answer_numnode\n",
    "    # pa: size & degree = |V| + |E|\n",
    "    number_of_parameter[\"hyperpa\"] = answer_numhedge + answer_numnode\n",
    "    if len(fflist[dataname]) > 0:\n",
    "        # ff : no\n",
    "        number_of_parameter[\"hyperff\"] = 2\n",
    "    if len(kronlist[dataname]) > 0:\n",
    "        # output_list & \n",
    "        d = pd.read_csv(\"../results/hyperk/{}/output_list.txt\".format(dataname))\n",
    "        path = d.iloc[kronlist[dataname][0]][\"modelpath\"]\n",
    "        print(path)\n",
    "        tmp = path.split(\"/\")[-2].split(\"_\")\n",
    "        initrow, initcol = int(tmp[0]), int(tmp[1])\n",
    "        number_of_parameter[\"hyperk\"] = initrow * initcol\n",
    "    \n",
    "    dataset2numparam[dataname] = number_of_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2result = defaultdict(dict)\n",
    "for dataname in dataset:\n",
    "    # print(dataname)\n",
    "    with open(outputdir + dataname + \"_final.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            tmp = line.rstrip().split(\"\\t\")\n",
    "            algoname = tmp[0]\n",
    "            result = float(tmp[1])\n",
    "            dataset2result[dataname][algoname] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {\n",
    "    \"answer\": \"black\",\n",
    "    \n",
    "    \"hyperk\": \"#4daf4a\",\n",
    "    \"hypercl\": \"#e6ab02\",\n",
    "    \"hyperlap\": \"#377eb8\",\n",
    "    \"hyperpa\": \"#984ea3\",\n",
    "    \"hypertr\": \"#ff7f00\",\n",
    "    \"hyperff\": \"#e41a1c\",\n",
    "}\n",
    "\n",
    "markerdict = {\n",
    "    \"email-Enron-full\": \"o\",\n",
    "    \"email-Eu-full\": \"o\",\n",
    "    \"contact-high-school\": \"^\",\n",
    "    \"contact-primary-school\": \"^\",\n",
    "    \"NDC-classes-full\": \"D\",\n",
    "    \"NDC-substances-full\": \"D\",\n",
    "    \"tags-ask-ubuntu\": \"P\",\n",
    "    \"tags-math-sx\": \"P\",\n",
    "    \"threads-ask-ubuntu\": \"s\",\n",
    "    \"threads-math-sx\": \"s\",\n",
    "    \"coauth-MAG-Geology-full\": \"<\",\n",
    "    \"coauth-MAG-History-full\": \"<\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata2norm = defaultdict(list)\n",
    "aggdata2rank = defaultdict(list)\n",
    "for dataname in dataset:\n",
    "    d = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in aggdata2norm:\n",
    "            aggdata2norm[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + [\"avg\"]:\n",
    "            aggdata2norm[algoname][evalname].append(row[evalname])\n",
    "    \n",
    "    d = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in aggdata2rank:\n",
    "            aggdata2rank[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + [\"avg\"]:\n",
    "            aggdata2rank[algoname][evalname].append(row[evalname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algoname in algolist:\n",
    "    for evalname in evallist + [\"avg\"]:\n",
    "        aggdata2norm[algoname][evalname] = np.mean(aggdata2norm[algoname][evalname])\n",
    "        aggdata2rank[algoname][evalname] = np.mean(aggdata2rank[algoname][evalname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist2rename = {\n",
    "    'deg': \"Degree\", \n",
    "    'sz': \"Size\", \n",
    "    'pd': \"Pair Degree\", \n",
    "    'its': \"Intersection\", \n",
    "    'cch': \"Clustering Coef.\", \n",
    "    'dst': \"Density\", \n",
    "    'ov': \"Overlapness\", \n",
    "    'sv': \"Singular value\", \n",
    "    'eff': \"Effective Diam.\", \n",
    "    \"avg\": \"Average\"\n",
    "}\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-panic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputpath = \"figure/fit/\"\n",
    "\n",
    "for evalname in evallist + [\"avg\"]:\n",
    "    plt.figure(figsize=(4,3.3), dpi=100)\n",
    "\n",
    "    for algoname in algolist:\n",
    "        numparam = aggdata2numparam[algoname]\n",
    "        if algoname not in dataset2result[dataname]:\n",
    "            continue\n",
    "        result = aggdata2norm[algoname][evalname]\n",
    "        if algoname == \"hyperk\":\n",
    "            plt.scatter(numparam, result, c=colordict[algoname], marker=\"*\", s=700, alpha=1.0)\n",
    "        else:\n",
    "            plt.scatter(numparam, result, c=colordict[algoname], s=400, alpha=1.0)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    plt.xlim(1, max(1, xmax*10))\n",
    "    if evalname == \"avg\":\n",
    "        plt.ylim(-1, 1)\n",
    "    else:\n",
    "        plt.ylim((min(-1, ymin-1), max(1, ymax+1)))\n",
    "    plt.ylabel(\"Z-score\", fontsize=24)\n",
    "    plt.xlabel(\"Number of Parameters\", fontsize=24)\n",
    "    plt.xscale(\"log\")\n",
    "    ax.tick_params(labelcolor='#4B4B4B', labelsize=22)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "    plt.savefig(outputpath + \"agg_{}_norm.jpg\".format(evalname), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-wholesale",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputpath = \"figure/fit/\"\n",
    "\n",
    "for evalname in evallist + [\"avg\"]:\n",
    "    plt.figure(figsize=(4,3.3), dpi=100)\n",
    "\n",
    "    for algoname in algolist:\n",
    "        numparam = aggdata2numparam[algoname]\n",
    "        if algoname not in dataset2result[dataname]:\n",
    "            continue\n",
    "        result = aggdata2rank[algoname][evalname]\n",
    "        if algoname == \"hyperk\":\n",
    "            plt.scatter(numparam, result, c=colordict[algoname], marker=\"*\", s=700, alpha=1.0)\n",
    "        else:\n",
    "            plt.scatter(numparam, result, c=colordict[algoname], s=400, alpha=1.0)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    plt.xlim(1, max(1, xmax*10))\n",
    "    plt.ylim((1, 6))\n",
    "    plt.ylabel(\"Ranking\", fontsize=24)\n",
    "    plt.xlabel(\"Number of Parameters\", fontsize=24)\n",
    "    plt.xscale(\"log\")\n",
    "    ax.tick_params(labelcolor='#4B4B4B', labelsize=22)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "    plt.savefig(outputpath + \"agg_{}_rank.jpg\".format(evalname), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-sense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-north",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

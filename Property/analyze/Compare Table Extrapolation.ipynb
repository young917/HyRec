{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-prairie",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_list = [\"NumHedge\", \"NumNode\", \"degree\", \"size\", \"pairdeg\", \"intersection\",\n",
    "             \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\",\n",
    "             \"sv\", \"effdiam\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"NumHedge\": \"E\", \n",
    "    \"NumNode\": \"V\",\n",
    "    \"degree\": \"deg\", \n",
    "    \"pairdeg\": \"pd\",\n",
    "    \"intersection\": \"its\", \n",
    "    \"size\": \"sz\",\n",
    "    \"clusteringcoef_hedge\": \"cch\",\n",
    "    \"density_dist\": \"dst\", \n",
    "    \"overlapness_dist\": \"ov\",\n",
    "    \"sv\": \"sv\", \n",
    "    \"effdiam\": \"eff\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def linearregression(X, Y, nolog=False):\n",
    "    if len(X) == 0:\n",
    "        return 0, 0, [0], 0\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y).reshape(-1, 1)\n",
    "    if nolog is False:\n",
    "        X = np.log2(X)\n",
    "        Y = np.log2(Y)\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    score = reg.score(X, Y)\n",
    "    coef = reg.coef_\n",
    "    assert len(coef) == 1\n",
    "    coef = coef[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "    pred = reg.predict(X).flatten()\n",
    "    pred = np.exp2(pred)\n",
    "\n",
    "    return score, coef, pred, intercept\n",
    "\n",
    "def read_properties(dataname, algoname, modelindex=-1):\n",
    "    if \"answer\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \".txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hypercl\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_cl.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperlap\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_lap.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperpa\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_pa.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"thera\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    elif \"hyperff\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "    else:\n",
    "        graphpath = \"../results/{}/{}/{}/hypergraph.txt\".format(algoname, dataname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "\n",
    "    return_dict = {}\n",
    "    dist = {}\n",
    "    print(graphpath)\n",
    "    \n",
    "    # Num Nodes & Num Edges\n",
    "    numhedge = 0\n",
    "    nodeset = set()\n",
    "    with open(graphpath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            hedge = line.rstrip().split(\",\")\n",
    "            for v in hedge:\n",
    "                nodeset.add(int(v))\n",
    "            numhedge += 1\n",
    "    numnode = len(nodeset)\n",
    "    return_dict[\"NumHedge\"] = numhedge\n",
    "    return_dict[\"NumNode\"] = numnode  \n",
    "    dist[\"NumHedge\"] = numhedge\n",
    "    dist[\"NumNode\"] = numnode    \n",
    "    \n",
    "    for distname in [\"degree\", \"pairdeg\", \"intersection\", \"size\"]:\n",
    "        dist[distname] = {}\n",
    "        X = []\n",
    "        with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                val, pdf = line.rstrip().split(\",\")\n",
    "                val, pdf = float(val), float(pdf)\n",
    "                if pdf == 0.0 or val == 0.0:\n",
    "                    continue\n",
    "                dist[distname][val] = pdf\n",
    "                X.append(val)\n",
    "        X = sorted(X)\n",
    "        Y = [dist[distname][x] for x in X]\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[distname] = (score, coef)\n",
    "        \n",
    "    for distname in [\"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "        dist[distname] = defaultdict(list)\n",
    "        X = []\n",
    "        try:\n",
    "            with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    val, pdf = line.rstrip().split(\",\")\n",
    "                    val, pdf = float(val), float(pdf)\n",
    "                    if val == 0.0 or pdf == 0.0:\n",
    "                        continue\n",
    "                    dist[distname][val].append(pdf)\n",
    "                    X.append(val)\n",
    "            X = sorted(X)\n",
    "            Y = []\n",
    "            for x in X:\n",
    "                y = np.mean(dist[distname][x])\n",
    "                dist[distname][x] = y\n",
    "                if y > 0:\n",
    "                    Y.append(y)\n",
    "                else:\n",
    "                    Y.append(1)\n",
    "            score, coef, pred, _ = linearregression(X, Y)\n",
    "            return_dict[distname] = (score, coef)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # SV    \n",
    "    with open(outputdir + \"sv.txt\", \"r\") as f:\n",
    "        tmp = {}\n",
    "        X = []\n",
    "        lsv = 0\n",
    "        for li, line in enumerate(f.readlines()):\n",
    "            sv = float(line.rstrip())\n",
    "            if li == 0:\n",
    "                lsv = sv\n",
    "            tmp[li + 1] = sv\n",
    "            X.append(li + 1)\n",
    "        X = sorted(X)\n",
    "        if dataname not in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:min(1000, int(len(X) * 0.5))]\n",
    "        elif dataname in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:1000]\n",
    "        elif dataname in [ \"coauth-MAG-Geology-full\", \"coauth-MAG-History-full\"]:\n",
    "            X = X[:500]\n",
    "        Y = [tmp[x] for x in X]\n",
    "\n",
    "        dist[\"sv\"] = {}\n",
    "        for x,y in zip(X, Y):\n",
    "            dist[\"sv\"][x] = y\n",
    "        dist[\"LargestSV\"] = lsv\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[\"sv\"] = (score, coef)\n",
    "\n",
    "\n",
    "    # EffDiam\n",
    "    with open(outputdir + \"effdiameter.txt\", \"r\") as f:\n",
    "        effdiam = 0\n",
    "        for line in f.readlines():\n",
    "            effdiam = float(line.rstrip())\n",
    "        return_dict[\"effdiam\"] = effdiam\n",
    "        dist[\"effdiam\"] = effdiam\n",
    "    \n",
    "    # SAVE\n",
    "    with open(outputdir + \"property.txt\", \"w\") as f:\n",
    "        f.write(\",\".join(columns) + \"\\n\")\n",
    "        tmp = []\n",
    "        for name in property_list:\n",
    "            if name in [\"LargestSV\", \"effdiam\", \"NumHedge\", \"NumNode\"]:\n",
    "                tmp.append(str(return_dict[name]))\n",
    "            else:\n",
    "                tmp1, tmp2 = return_dict[name]\n",
    "                tmp.append(str(tmp1))\n",
    "                tmp.append(str(tmp2))\n",
    "        f.write(\",\".join(tmp))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    return return_dict, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(_dict):\n",
    "    cumulated_x = sorted(list(_dict.keys()))\n",
    "    cdf = {}\n",
    "    cum = 0\n",
    "\n",
    "    for _x in cumulated_x:\n",
    "        cum += _dict[_x]\n",
    "        cdf[_x] = cum\n",
    "        assert cum < 1.1\n",
    "        \n",
    "    return cdf\n",
    "\n",
    "def get_cumul_dist(dict_x1, dict_x2):\n",
    "    cdf1 = get_cdf(dict_x1)\n",
    "    x1 = list(cdf1.keys())\n",
    "    cdf2 = get_cdf(dict_x2)\n",
    "    x2 = list(cdf2.keys())\n",
    "    \n",
    "    cum1, cum2 = 0, 0\n",
    "    maxdiff = 0\n",
    "    for x in sorted(list(set(x1 + x2))):\n",
    "        if x in x1:\n",
    "            cum1 = cdf1[x]\n",
    "        if x in x2:\n",
    "            cum2 = cdf2[x]\n",
    "        if abs(cum1 - cum2) > maxdiff:\n",
    "            maxdiff = abs(cum1 - cum2)\n",
    "    \n",
    "    return maxdiff\n",
    "\n",
    "    \n",
    "def get_rmse_dist(dict_x1, dict_x2, set_length=False, normalize=False):\n",
    "    total = 0\n",
    "    maxy1 = 0\n",
    "    \n",
    "    x1s = list(dict_x1.keys())\n",
    "    x2s = list(dict_x2.keys())\n",
    "    \n",
    "    if set_length:\n",
    "        keys = x1s\n",
    "    else:\n",
    "        keys = set(x1s+x2s)\n",
    "    \n",
    "    for x in keys:\n",
    "        y1, y2 = 0, 0\n",
    "        if x in x1s:\n",
    "            y1 = dict_x1[x]\n",
    "            if maxy1 < y1:\n",
    "                maxy1 = y1\n",
    "        if x in x2s:\n",
    "            y2 = dict_x2[x]\n",
    "        \n",
    "        total += (y1 - y2) ** 2\n",
    "    \n",
    "    total /= len(keys)\n",
    "    total = total ** 0.5\n",
    "    \n",
    "    if normalize:\n",
    "        total /= maxy1\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldatalist = {\n",
    "    \"email-Enron-half\": \"email-Enron-full\",\n",
    "    \"email-Eu-half\": \"email-Eu-full\",\n",
    "    \"contact-primary-school-half\": \"contact-primary-school\",\n",
    "    \"contact-high-school-half\": \"contact-high-school\",\n",
    "    \"NDC-classes-half\": \"NDC-classes-full\",\n",
    "    \"NDC-substances-half\": \"NDC-substances-full\",\n",
    "    \"tags-ask-ubuntu-half\": \"tags-ask-ubuntu\", \n",
    "    \"tags-math-sx-half\": \"tags-math-sx\",\n",
    "    \"threads-ask-ubuntu-half\": \"threads-ask-ubuntu\", \n",
    "    \"threads-math-sx-half\": \"threads-math-sx\"\n",
    "}\n",
    "\n",
    "\n",
    "halfdatalist = {\n",
    "    \"email-Enron-full\" : \"email-Enron-half\",\n",
    "    \"email-Eu-full\" : \"email-Eu-half\",\n",
    "    \"contact-primary-school\" : \"contact-primary-school-half\",\n",
    "    \"contact-high-school\" : \"contact-high-school-half\",\n",
    "    \"NDC-classes-full\" : \"NDC-classes-half\",\n",
    "    \"NDC-substances-full\" : \"NDC-substances-half\",\n",
    "    \"tags-ask-ubuntu\": \"tags-ask-ubuntu-half\",\n",
    "    \"tags-math-sx\": \"tags-math-sx-half\",\n",
    "    \"threads-ask-ubuntu\": \"threads-ask-ubuntu-half\",\n",
    "    \"threads-math-sx\": \"threads-math-sx-half\",\n",
    "}\n",
    "\n",
    "datalist = [\"email-Enron-full\", \"email-Eu-full\",\n",
    "           \"contact-primary-school\", \"contact-high-school\",\n",
    "           \"NDC-classes-full\", \"NDC-substances-full\",\n",
    "           \"tags-ask-ubuntu\", \"tags-math-sx\",\n",
    "           \"threads-ask-ubuntu\", \"threads-math-sx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-coral",
   "metadata": {},
   "source": [
    "# Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = datalist[9]\n",
    "print(dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [(\"answer\", -1)] # (\"hypercl\", -1), (\"hyperunif\", -1),\n",
    "    \n",
    "fflist = {\n",
    "    # When hyperparameter fitting half\n",
    "    \"email-Enron-half\": [\"0.45_0.3\"],\n",
    "    \"email-Eu-half\": [\"0.51_0.3\"],\n",
    "    \"contact-high-school-half\": [\"0.51_0.3\"],\n",
    "    \"contact-primary-school-half\": [\"0.51_0.2\"],\n",
    "    \"NDC-classes-half\": [\"0.45_0.3\"],\n",
    "    \"NDC-substances-half\": [\"0.45_0.3\"],\n",
    "    \"tags-ask-ubuntu-half\": [\"0.51_0.3\"],\n",
    "    \"tags-math-sx-half\": [\"0.51_0.3\"],\n",
    "    \"threads-ask-ubuntu-half\": [\"0.45_0.2\"],\n",
    "    \"threads-math-sx-half\": [\"0.45_0.3\"]\n",
    "}\n",
    "\n",
    "namelist = [(\"answer\", -1)]\n",
    "if len(fflist[halfdatalist[dataname]]) > 0:\n",
    "    namelist.append((\"hyperff\", fflist[halfdatalist[dataname]][0]))\n",
    "if len(kronlist[halfdatalist[dataname]]) > 0:\n",
    "    namelist.append((\"hyperk\", 0)) # assume there exist just one generated hypergraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfindex_2_fullindex(dataname, index):\n",
    "    check_tmp = {}\n",
    "    \n",
    "    d = pd.read_csv(\"../results/hyperk_half/{}/output_list.txt\".format(dataname))\n",
    "    for irow, row in d.iterrows():\n",
    "        model_index = row[\"modelIndex\"]\n",
    "        path = row[\"modelpath\"]\n",
    "        check_tmp[path] = model_index\n",
    "        \n",
    "    ret = -1\n",
    "    d = pd.read_csv(\"../results/hyperk/{}/output_list.txt\".format(dataname))\n",
    "    for irow, row in d.iterrows():\n",
    "        model_index = row[\"modelIndex\"]\n",
    "        path = row[\"modelpath\"]\n",
    "        if path in check_tmp and check_tmp[path] == index:\n",
    "            ret = model_index\n",
    "            break\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_list = [\"degree\", \"size\", \"pairdeg\", \"intersection\",\"sv\", \n",
    "             \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\", \"effdiam\"]\n",
    "\n",
    "evallist = ['deg', 'sz', 'pd', 'its', 'cch', 'dst', 'ov', 'sv', 'eff'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-sphere",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputdir = \"csv/sv_forecast/\"\n",
    "if os.path.isdir(outputdir) is False:\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "outputpath = outputdir + dataname + \".txt\"\n",
    "columns = [column_mapping[prop] for prop in property_list]\n",
    "with open(outputpath, \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\", \"AlgoOpt\"] + columns) + \"\\n\")\n",
    "\n",
    "for name, modelindex in namelist:\n",
    "    if name == \"answer\":\n",
    "        ret, dist = read_properties(dataname, name, modelindex)\n",
    "        ret_answer = ret\n",
    "        dist_answer = dist   \n",
    "        continue\n",
    "    elif name == \"hyperk\":\n",
    "        full_index = halfindex_2_fullindex(halfdatalist[dataname], modelindex)\n",
    "        ret, dist = read_properties(halfdatalist[dataname], name, full_index)\n",
    "    else:\n",
    "        ret, dist = read_properties(dataname, name, modelindex)\n",
    "\n",
    "    difflist = []\n",
    "    for prop in property_list:\n",
    "        if prop in [\"degree\", \"size\", \"pairdeg\", \"intersection\"]:\n",
    "            diff = get_cumul_dist(dist_answer[prop], dist[prop])\n",
    "        elif prop in [\"sv\"]:\n",
    "            diff = get_rmse_dist(dist_answer[prop], dist[prop], set_length=True, normalize=False)\n",
    "        elif prop in [\"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "            diff = get_rmse_dist(dist_answer[prop], dist[prop], normalize=False)\n",
    "        elif prop in [\"effdiam\"]:\n",
    "            diff = abs(dist[prop] - dist_answer[prop]) / dist_answer[prop]\n",
    "        difflist.append(str(diff))\n",
    "\n",
    "    with open(outputpath, \"a\") as f:\n",
    "        algoopt = str(modelindex)\n",
    "        algoname = name\n",
    "        f.write(\",\".join([algoname, algoopt] + difflist) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = ['deg', 'sz', 'pd', 'its', 'cch', 'dst', 'ov', 'sv', 'eff'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "target = d[evallist]\n",
    "d['avg'] = target.mean(axis=1)\n",
    "# d = d.sort_values(by=\"sv\")\n",
    "d = d.sort_values(by=\"avg\")\n",
    "d.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-fault",
   "metadata": {},
   "source": [
    "# NORM & RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Normalize Result\n",
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "for col in evallist:\n",
    "    if d[col].std() != 0:\n",
    "        d[col] = (d[col] - d[col].mean()) / d[col].std()\n",
    "norms = d[evallist]\n",
    "d['avg'] = norms.mean(axis=1)\n",
    "# d = d.sort_values(by=[\"avg\"], ascending=True)\n",
    "d.to_csv(outputdir + dataname + \"_norm.txt\", index=False)\n",
    "\n",
    "# Make Ranking Result\n",
    "d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "for ename in evallist:\n",
    "    d[ename] = d[ename].abs().rank(method='min')\n",
    "ranks = d[evallist]\n",
    "d['avg'] = ranks.mean(axis=1)\n",
    "# d = d.sort_values(by=[\"avg\"], ascending=True)\n",
    "d.to_csv(outputdir + dataname + \"_rank.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norm\n",
    "nd = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "nd = nd.sort_values(by=[\"avg\"], ascending=True)\n",
    "nd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-doctor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rank\n",
    "rd = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "rd = rd.sort_values(by=[\"avg\"], ascending=True)\n",
    "rd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-editing",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"email-Enron-full\", \"email-Eu-full\",\n",
    "           \"contact-high-school\", \"contact-primary-school\",\n",
    "          \"NDC-classes-full\", \"NDC-substances-full\"\n",
    "           ,\"tags-ask-ubuntu\", \"tags-math-sx\",\n",
    "          \"threads-ask-ubuntu\", \"threads-math-sx\"]\n",
    "\n",
    "algolist = [\"hyperff\", \"hyperk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2result = defaultdict(dict)\n",
    "algo2norm = defaultdict(dict)\n",
    "algo2rank = defaultdict(dict)\n",
    "\n",
    "for dataname in dataset:    \n",
    "    d = pd.read_csv(outputdir + dataname + \".txt\")\n",
    "    target = d[evallist]\n",
    "    d['avg'] = target.mean(axis=1)\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in algo2result:\n",
    "            algo2result[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + ['avg']:\n",
    "            algo2result[algoname][evalname].append(row[evalname])\n",
    "\n",
    "    d = pd.read_csv(outputdir + dataname + \"_rank.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in algo2rank:\n",
    "            algo2rank[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + ['avg']:\n",
    "            algo2rank[algoname][evalname].append(row[evalname])\n",
    "    \n",
    "    d = pd.read_csv(outputdir + dataname + \"_norm.txt\")\n",
    "    for irow, row in d.iterrows():\n",
    "        algoname = row[\"AlgoName\"]\n",
    "        if algoname not in algo2norm:\n",
    "            algo2norm[algoname] = defaultdict(list)\n",
    "        for evalname in evallist + ['avg']:\n",
    "            algo2norm[algoname][evalname].append(row[evalname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algoname in algolist:\n",
    "    for evalname in evallist + ['avg']:\n",
    "        algo2result[algoname][evalname] = np.mean(algo2result[algoname][evalname])\n",
    "        algo2rank[algoname][evalname] = np.mean(algo2rank[algoname][evalname])\n",
    "        algo2norm[algoname][evalname] = np.mean(algo2norm[algoname][evalname])\n",
    "    \n",
    "with open(outputdir + \"agg.txt\", \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\"] + evallist + [\"avg\"]) + \"\\n\")\n",
    "    for algoname in algolist:\n",
    "        res = [str(algo2result[algoname][evalname]) for evalname in evallist + ['avg']]\n",
    "        f.write(\",\".join([algoname] + res) + \"\\n\")\n",
    "        \n",
    "        \n",
    "with open(outputdir + \"agg_rank.txt\", \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\"] + evallist + [\"avg\"]) + \"\\n\")\n",
    "    for algoname in algolist:\n",
    "        res = [str(algo2rank[algoname][evalname]) for evalname in evallist + ['avg']]\n",
    "        f.write(\",\".join([algoname] + res) + \"\\n\")\n",
    "        \n",
    "        \n",
    "with open(outputdir + \"agg_norm.txt\", \"w\") as f:\n",
    "    f.write(\",\".join([\"AlgoName\"] + evallist + [\"avg\"]) + \"\\n\")\n",
    "    for algoname in algolist:\n",
    "        res = [str(algo2norm[algoname][evalname]) for evalname in evallist + ['avg']]\n",
    "        f.write(\",\".join([algoname] + res) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(outputdir + \"agg.txt\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.read_csv(outputdir + \"agg_rank.txt\")\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = pd.read_csv(outputdir + \"agg_norm.txt\")\n",
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2rank = defaultdict(dict)\n",
    "algo2norm = defaultdict(dict)\n",
    "rd = pd.read_csv(outputdir + \"agg_rank.txt\")\n",
    "for irow, row in rd.iterrows():\n",
    "    algoname = row[\"AlgoName\"]\n",
    "    for evalname in evallist + [\"avg\"]:\n",
    "        algo2rank[algoname][evalname] = row[evalname]\n",
    "nd = pd.read_csv(outputdir + \"agg_norm.txt\")\n",
    "for irow, row in nd.iterrows():\n",
    "    algoname = row[\"AlgoName\"]\n",
    "    for evalname in evallist + [\"avg\"]:\n",
    "        algo2norm[algoname][evalname] = row[evalname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval2rankbest = defaultdict(float)\n",
    "for evalname in evallist + [\"avg\"]:\n",
    "    for algoname in algolist:\n",
    "        curval = algo2rank[algoname][evalname]\n",
    "        if evalname not in eval2rankbest:\n",
    "            eval2rankbest[evalname] = curval\n",
    "        elif eval2rankbest[evalname] > curval:\n",
    "            eval2rankbest[evalname] = curval\n",
    "eval2normbest = defaultdict(float)\n",
    "for evalname in evallist + [\"avg\"]:\n",
    "    for algoname in algolist:\n",
    "        curval = algo2norm[algoname][evalname]\n",
    "        if evalname not in eval2normbest:\n",
    "            eval2normbest[evalname] = curval\n",
    "        elif eval2normbest[evalname] > curval:\n",
    "            eval2normbest[evalname] = curval\n",
    "\n",
    "for algoname in algolist:\n",
    "    for evalname in evallist + [\"avg\"]:\n",
    "        currank = algo2rank[algoname][evalname]\n",
    "        curnorm = algo2norm[algoname][evalname]\n",
    "        if currank == eval2rankbest[evalname]:\n",
    "            print(\"& \\\\textbf{%.2f} \" % (currank), end=\"\")\n",
    "        else:\n",
    "            print(\"& %.2f \" % (currank), end=\"\")\n",
    "        if curnorm == eval2normbest[evalname]:\n",
    "            print(\"(\\\\textbf{%.2f}) \" % (curnorm), end=\"\")\n",
    "        else:\n",
    "            print(\"(%.2f) \" % (curnorm), end=\"\")\n",
    "            \n",
    "    print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-library",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-stationery",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"E\", \"V\", \n",
    " \"deg score\", \"deg coef\", \"sz score\", \"sz coef\",\n",
    " \"pd score\", \"pd coef\", \"its score\", \"its coef\", \n",
    " \"cc score\", \"cc coef\", \"cch score\", \"cch coef\", \n",
    " \"dst score\", \"dst coef\", \"ov score\", \"ov coef\",\n",
    " \"lsv\", \"sv score\", \"sv coef\", \"eff\"]\n",
    "\n",
    "property_list = [\"NumHedge\", \"NumNode\", \"degree\", \"size\", \"pairdeg\", \"intersection\",\n",
    "             \"clusteringcoef\", \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\",\n",
    "             \"LargestSV\", \"sv\", \"effdiam\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"NumHedge\": \"E\", \"NumNode\": \"V\",\n",
    "    \"degree\": \"deg\", \"pairdeg\": \"pd\",\n",
    "    \"intersection\": \"its\", \"size\": \"sz\",\n",
    "    \"clusteringcoef\": \"cc\", \"clusteringcoef_hedge\": \"cch\",\n",
    "    \"density_dist\": \"dst\", \"overlapness_dist\": \"ov\",\n",
    "    \"LargestSV\": \"lsv\", \"sv\": \"sv\", \n",
    "    \"effdiam\": \"eff\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def linearregression(X, Y, nolog=False):\n",
    "    if len(X) == 0:\n",
    "        return 0, 0, [0], 0\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y).reshape(-1, 1)\n",
    "    if nolog is False:\n",
    "        X = np.log2(X)\n",
    "        Y = np.log2(Y)\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    score = reg.score(X, Y)\n",
    "    coef = reg.coef_\n",
    "    assert len(coef) == 1\n",
    "    coef = coef[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "    pred = reg.predict(X).flatten()\n",
    "    pred = np.exp2(pred)\n",
    "\n",
    "    return score, coef, pred, intercept\n",
    "\n",
    "def read_properties(dataname, algoname, modelindex=-1):\n",
    "    if \"answer\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \".txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hypercl\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_cl.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"hyperlap\" == algoname:\n",
    "        graphpath = \"../dataset/\" + dataname + \"_lap.txt\"\n",
    "        outputdir = \"../results/{}/{}/\".format(algoname, dataname)\n",
    "    elif \"thera\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname,dataname, modelindex)\n",
    "    elif \"hyperff\" == algoname:\n",
    "        graphpath = \"../dataset/{}_{}_{}.txt\".format(dataname, algoname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname,dataname, modelindex)\n",
    "    else:\n",
    "        graphpath = \"../results/{}/{}/{}/hypergraph.txt\".format(algoname, dataname, modelindex)\n",
    "        outputdir = \"../results/{}/{}/{}/\".format(algoname, dataname, modelindex)\n",
    "\n",
    "    return_dict = {}\n",
    "    dist = {}\n",
    "    print(graphpath)\n",
    "    print(outputdir)\n",
    "    \n",
    "    # Num Nodes & Num Edges\n",
    "    numhedge = 0\n",
    "    nodeset = set()\n",
    "    with open(graphpath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            hedge = line.rstrip().split(\",\")\n",
    "            for v in hedge:\n",
    "                nodeset.add(int(v))\n",
    "            numhedge += 1\n",
    "    numnode = len(nodeset)\n",
    "    return_dict[\"NumHedge\"] = numhedge\n",
    "    return_dict[\"NumNode\"] = numnode  \n",
    "    dist[\"NumHedge\"] = numhedge\n",
    "    dist[\"NumNode\"] = numnode    \n",
    "    \n",
    "    for distname in [\"degree\", \"pairdeg\", \"intersection\", \"size\"]:\n",
    "        dist[distname] = {}\n",
    "        X = []\n",
    "        with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                val, pdf = line.rstrip().split(\",\")\n",
    "                val, pdf = float(val), float(pdf)\n",
    "                if pdf == 0.0 or val == 0.0:\n",
    "                    continue\n",
    "                dist[distname][val] = pdf\n",
    "                X.append(val)\n",
    "        X = sorted(X)\n",
    "        Y = [dist[distname][x] for x in X]\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[distname] = (score, coef)\n",
    "        \n",
    "    for distname in [ \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]:\n",
    "        dist[distname] = defaultdict(list)\n",
    "        X = []\n",
    "        try:\n",
    "            with open(outputdir + distname + \".txt\", \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    val, pdf = line.rstrip().split(\",\")\n",
    "                    val, pdf = float(val), float(pdf)\n",
    "                    if val == 0.0 or pdf == 0.0:\n",
    "                        continue\n",
    "                    dist[distname][val].append(pdf)\n",
    "                    X.append(val)\n",
    "            X = sorted(X)\n",
    "            Y = []\n",
    "            for x in X:\n",
    "                y = np.mean(dist[distname][x])\n",
    "                dist[distname][x] = y\n",
    "                if y > 0:\n",
    "                    Y.append(y)\n",
    "                else:\n",
    "                    Y.append(1)\n",
    "            score, coef, pred, _ = linearregression(X, Y)\n",
    "            return_dict[distname] = (score, coef)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    with open(outputdir + \"sv.txt\", \"r\") as f:\n",
    "        tmp = {}\n",
    "        X = []\n",
    "        lsv = 0\n",
    "        for li, line in enumerate(f.readlines()):\n",
    "            sv = float(line.rstrip())\n",
    "            if li == 0:\n",
    "                lsv = sv\n",
    "            tmp[li + 1] = sv\n",
    "            X.append(li + 1)\n",
    "        X = sorted(X)\n",
    "        if dataname not in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:min(1000, int(len(X) * 0.5))]\n",
    "        elif dataname in [\"tags-ask-ubuntu\", \"tags-math-sx\", \"threads-ask-ubuntu\", \"threads-math-sx\"]:\n",
    "            X = X[:1000]\n",
    "        elif dataname in [ \"coauth-MAG-Geology-full\", \"coauth-MAG-History-full\"]:\n",
    "            X = X[:500]\n",
    "        Y = [tmp[x] for x in X]\n",
    "\n",
    "        dist[\"sv\"] = {}\n",
    "        for x,y in zip(X, Y):\n",
    "            dist[\"sv\"][x] = y\n",
    "        dist[\"LargestSV\"] = lsv\n",
    "        score, coef, pred, _ = linearregression(X, Y)\n",
    "        return_dict[\"sv\"] = (score, coef)\n",
    "\n",
    "    # EffDiam\n",
    "    with open(outputdir + \"effdiameter.txt\", \"r\") as f:\n",
    "        effdiam = 0\n",
    "        for line in f.readlines():\n",
    "            effdiam = float(line.rstrip())\n",
    "        return_dict[\"effdiam\"] = effdiam\n",
    "        dist[\"effdiam\"] = effdiam\n",
    "\n",
    "    return return_dict, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(_dict):\n",
    "    cumulated_x = sorted(list(_dict.keys()))\n",
    "    cdf = {}\n",
    "    cum = 0\n",
    "\n",
    "    for _x in cumulated_x:\n",
    "        cum += _dict[_x]\n",
    "        cdf[_x] = cum\n",
    "        assert cum < 1.1\n",
    "        \n",
    "    return cdf\n",
    "\n",
    "def get_cumul_dist(dict_x1, dict_x2):\n",
    "    cdf1 = get_cdf(dict_x1)\n",
    "    x1 = list(cdf1.keys())\n",
    "    cdf2 = get_cdf(dict_x2)\n",
    "    x2 = list(cdf2.keys())\n",
    "    \n",
    "    cum1, cum2 = 0, 0\n",
    "    maxdiff = 0\n",
    "    for x in sorted(list(set(x1 + x2))):\n",
    "        if x in x1:\n",
    "            cum1 = cdf1[x]\n",
    "        if x in x2:\n",
    "            cum2 = cdf2[x]\n",
    "        if abs(cum1 - cum2) > maxdiff:\n",
    "            maxdiff = abs(cum1 - cum2)\n",
    "    \n",
    "    return maxdiff\n",
    "\n",
    "    \n",
    "def get_rmse_dist(dict_x1, dict_x2, normalize=False):\n",
    "    total = 0\n",
    "    \n",
    "    maxy1 = 0\n",
    "    \n",
    "    x1s = list(dict_x1.keys())\n",
    "    x2s = list(dict_x2.keys())\n",
    "    for x in set(x1s + x2s):\n",
    "        y1, y2 = 0, 0\n",
    "        if x in x1s:\n",
    "            y1 = dict_x1[x]\n",
    "            if maxy1 < y1:\n",
    "                maxy1 = y1\n",
    "        if x in x2s:\n",
    "            y2 = dict_x2[x]\n",
    "        \n",
    "        total += (y1 - y2) ** 2\n",
    "    \n",
    "    total /= len(set(x1s + x2s))\n",
    "    total = total ** 0.5\n",
    "    \n",
    "    if normalize:\n",
    "        total /= maxy1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_result_dir = \"hyperk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-guard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabeldict = {\n",
    "    \"degree\": \"Node degree\",\n",
    "    \"size\": \"Hyperedge size\",\n",
    "    \"pairdeg\": \"Degree of node pairs\",\n",
    "    \"intersection\": \"Intersection size\",\n",
    "    \"sv\": \"Rank\",\n",
    "    \"clusteringcoef_hedge\": \"Node degree\",\n",
    "    \"density_dist\": \"# of nodes\",\n",
    "    \"overlapness_dist\": \"# of nodes\",\n",
    "}\n",
    "\n",
    "ylabeldict = {\n",
    "    \"degree\": \"OddsRatio\",\n",
    "    \"size\": \"OddsRatio\",\n",
    "    \"pairdeg\": \"PDF\",\n",
    "    \"intersection\": 'PDF',\n",
    "    \"sv\": \"Singular value\",\n",
    "    \"clusteringcoef_hedge\": \"# of inter- \\n secting pairs\",\n",
    "    \"density_dist\": \"# of hyperedges\",\n",
    "    \"overlapness_dist\": r\"$\\sum$ hyperedge sizes\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    1: {\n",
    "        \"answer\": \"gray\",\n",
    "        \"hyperk\": \"#66a61e\",\n",
    "        \"hypercl\": \"#ffffb3\",\n",
    "        \"hyperlap\": \"#80b1d3\",\n",
    "        \"hyperpa\": \"#bebada\",\n",
    "        \"thera\": \"#fb9a99\",\n",
    "        \"hyperff\": \"#fb8072\",\n",
    "    },\n",
    "    0: {\n",
    "        \"answer\": \"black\",\n",
    "        \"hyperk\": \"#4daf4a\",\n",
    "        \"hypercl\": \"#ffff33\",\n",
    "        \"hyperlap\": \"#377eb8\",\n",
    "        \"hyperpa\": \"#984ea3\",\n",
    "        \"thera\": \"#ff7f00\",\n",
    "        \"hyperff\": \"#e41a1c\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldatalist = {\n",
    "    \"email-Enron-half\": \"email-Enron-full\",\n",
    "    \"email-Eu-half\": \"email-Eu-full\",\n",
    "    \"contact-primary-school-half\": \"contact-primary-school\",\n",
    "    \"contact-high-school-half\": \"contact-high-school\",\n",
    "    \"NDC-classes-half\": \"NDC-classes-full\",\n",
    "    \"NDC-substances-half\": \"NDC-substances-full\",\n",
    "    \"tags-ask-ubuntu-half\": \"tags-ask-ubuntu\", \n",
    "    \"tags-math-sx-half\": \"tags-math-sx\",\n",
    "    \"threads-ask-ubuntu-half\": \"threads-ask-ubuntu\", \n",
    "    \"threads-math-sx-half\": \"threads-math-sx\"\n",
    "}\n",
    "\n",
    "\n",
    "halfdatalist = {\n",
    "    \"email-Enron-full\" : \"email-Enron-half\",\n",
    "    \"email-Eu-full\" : \"email-Eu-half\",\n",
    "    \"contact-primary-school\" : \"contact-primary-school-half\",\n",
    "    \"contact-high-school\" : \"contact-high-school-half\",\n",
    "    \"NDC-classes-full\" : \"NDC-classes-half\",\n",
    "    \"NDC-substances-full\" : \"NDC-substances-half\",\n",
    "    \"tags-ask-ubuntu\": \"tags-ask-ubuntu-half\",\n",
    "    \"tags-math-sx\": \"tags-math-sx-half\",\n",
    "    \"threads-ask-ubuntu\": \"threads-ask-ubuntu-half\",\n",
    "    \"threads-math-sx\": \"threads-math-sx-half\",\n",
    "}\n",
    "\n",
    "datalist = [\"email-Enron-half\", \"email-Eu-half\",\n",
    "            \"contact-primary-school-half\", \"contact-high-school-half\",\n",
    "            \"NDC-classes-half\", \"NDC-substances-half\",\n",
    "           \"tags-ask-ubuntu-half\", \"tags-math-sx-half\",\n",
    "           \"threads-ask-ubuntu-half\", \"threads-math-sx-half\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-treaty",
   "metadata": {},
   "source": [
    "# Set Dataname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = datalist[8]\n",
    "print(dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fflist = {\n",
    "    # When hyperparameter fitting half\n",
    "    \"email-Enron-half\": [\"0.45_0.3\"],\n",
    "    \"email-Eu-half\": [\"0.51_0.3\"],\n",
    "    \"contact-high-school-half\": [\"0.51_0.3\"],\n",
    "    \"contact-primary-school-half\": [\"0.51_0.2\"],\n",
    "    \"NDC-classes-half\": [\"0.45_0.3\"],\n",
    "    \"NDC-substances-half\": [\"0.45_0.3\"],\n",
    "    \"tags-ask-ubuntu-half\": [\"0.51_0.3\"],\n",
    "    \"tags-math-sx-half\": [\"0.51_0.3\"],\n",
    "    \"threads-ask-ubuntu-half\": [\"0.45_0.2\"],\n",
    "    \"threads-math-sx-half\": [\"0.45_0.3\"],\n",
    "}\n",
    "\n",
    "namelist = [(\"answer\", -1)]\n",
    "if len(fflist[dataname]) > 0:\n",
    "    namelist.append((\"hyperff\", fflist[dataname][0]))\n",
    "if len(kronlist[dataname]) > 0:\n",
    "    namelist.append((\"hyperk\", 0)) # assume there exist just one generated hypergraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfindex_2_fullindex(dataname, index):\n",
    "    check_tmp = {}\n",
    "    \n",
    "    d = pd.read_csv(\"../results/hyperk_half/{}/output_list.txt\".format(dataname))\n",
    "    for irow, row in d.iterrows():\n",
    "        model_index = row[\"modelIndex\"]\n",
    "        path = row[\"modelpath\"]\n",
    "        check_tmp[path] = model_index\n",
    "        \n",
    "    ret = -1\n",
    "    if flag:\n",
    "        d = pd.read_csv(\"../results/hyperk/{}/output_list.txt\".format(dataname))\n",
    "    else:\n",
    "        d = pd.read_csv(\"../results/hyperk/{}/output_list.txt\".format(dataname))\n",
    "    for irow, row in d.iterrows():\n",
    "        model_index = row[\"modelIndex\"]\n",
    "        path = row[\"modelpath\"]\n",
    "        if path in check_tmp and check_tmp[path] == index:\n",
    "            ret = model_index\n",
    "            break\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "styledict = {\n",
    "    0: \"dashed\",\n",
    "    1: \"solid\"\n",
    "}\n",
    "\n",
    "markerdict = {\n",
    "    1: \"^\",\n",
    "    0: \"o\"\n",
    "}\n",
    "\n",
    "alphadict = {\n",
    "    1: 0.9,\n",
    "    0: 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    \"answer\": \"ANSWER\",\n",
    "    \"hypercl\" : \"HyperCL\",\n",
    "    \"hyperlap\" : \"HyperLAP\",\n",
    "    \"hyperpa\" : \"HyperPA\",\n",
    "    \"hyperff\" : \"HyperFF\",\n",
    "    \"thera\" : \"THera\", \n",
    "    \"hyperk\" : \"HyperK\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "distset = [\"degree\", \"size\", \"pairdeg\", \"intersection\", \"sv\", \n",
    "           \"clusteringcoef_hedge\", \"density_dist\", \"overlapness_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-retrieval",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for distname in distset:\n",
    "    min_x = 1\n",
    "    max_x = 0\n",
    "\n",
    "    for di, cur_dataname in enumerate([fulldatalist[dataname], dataname]):\n",
    "        outputpath = \"figure/forecast/\" + dataname + \"/\"\n",
    "        if os.path.isdir(outputpath) is False:\n",
    "            os.makedirs(outputpath)\n",
    "        if di == 1:\n",
    "            outputpath += distname + \"_past.jpg\"\n",
    "        else:\n",
    "            outputpath += distname + \"_pred.jpg\"\n",
    "        \n",
    "        print(outputpath)\n",
    "\n",
    "        plt.figure(figsize=(5,4), dpi=100)\n",
    "        for (name, idx) in namelist:\n",
    "            if name == \"answer\":\n",
    "                ret, dist = read_properties(cur_dataname, name, idx)\n",
    "                ret_answer = ret\n",
    "                dist_answer = dist \n",
    "            elif name == \"hyperk\":                    \n",
    "                if di == 1: # half\n",
    "                    ret, dist = read_properties(cur_dataname, \"hyperk_half\", idx)\n",
    "                else: # full\n",
    "                    print(halfdatalist[cur_dataname])\n",
    "                    full_idx = halfindex_2_fullindex(halfdatalist[cur_dataname], idx)\n",
    "                    ret, dist = read_properties(halfdatalist[cur_dataname], \"hyperk\", full_idx)\n",
    "            else:\n",
    "                ret, dist = read_properties(cur_dataname, name, idx)\n",
    "            algoname = rename[name]\n",
    "\n",
    "            # PLOT!\n",
    "            target_dist = dist[distname]\n",
    "            x = sorted(list(target_dist.keys()))\n",
    "            if distname == \"sv\":\n",
    "                x = x[:len(dist_answer[distname].keys())]\n",
    "            if di == 0 and max(x) > max_x:\n",
    "                max_x = max(x)\n",
    "            y = [target_dist[_x] for _x in x]\n",
    "            score, coef, pred, intercept = linearregression(x, y)\n",
    "            \n",
    "            if name in [\"answer\"]:\n",
    "                plt.scatter(x, y, label=algoname + \"_\" + str(di), c=color[di][name], alpha=alphadict[di], s=100, marker=markerdict[di], zorder=2)\n",
    "            elif name in [\"hypercl\", \"hyperlap\", \"hyperff\", \"thera\"]:\n",
    "                plt.scatter(x, y, label=algoname + \"_\" + str(di), c=color[di][name], alpha=alphadict[di], s=100, marker=markerdict[di], zorder=2)\n",
    "            else:\n",
    "                plt.scatter(x, y, label=algoname + \"_\" + str(di), c=color[di][name], s= 100, marker=markerdict[di], zorder=2)\n",
    "            \n",
    "#         if di == 0:\n",
    "#             plt.plot(answer[1][\"X\"], answer[1][\"Y\"], label=\"answer_1\", \n",
    "#                      color=color[1][\"answer\"], alpha=0.3, markersize=5, marker=markerdict[1], linestyle=\"dashed\", zorder=1)\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim((min_x / 2, max_x * (2**0.5)))\n",
    "        \n",
    "        plt.xscale(\"log\", base=2)\n",
    "        plt.yscale(\"log\", base=2)\n",
    "        \n",
    "        ax.tick_params(labelcolor='#4B4B4B', labelsize=22)\n",
    "        plt.xlabel(xlabeldict[distname], fontsize=24)\n",
    "        plt.ylabel(ylabeldict[distname], fontsize=24)\n",
    "            \n",
    "        plt.savefig(outputpath, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-bryan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-award",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
